Title,Description,Issue ID,URL,State,Author,Author Username,Assignee,Assignee Username,Confidential,Locked,Due Date,Created At (UTC),Updated At (UTC),Closed At (UTC),Milestone,Weight,Labels,Time Estimate,Time Spent,Epic ID,Epic Title
API Endpunkt - Aktualisierung einer Sprechblase (Backend-Sicht),"Als Frontend benötige ich Schnittstellen im Backend zur Annahme und Weitergabe der Untertitel und Sprechblasen, sodass ich die Untertitel darstellen kann. Wir benötigen also einen REST Endpunkt, den das Frontend aufrufen kann, sobald eine Sprechblase aktualisiert wurde.

**DoD**

Im Backend existieren REST-Endpunkte für:
- [x] Endpunkt im Backend, der die aktualisierte Sprechblase entgegennimmt und in die interne Datenstruktur des Backends schreibt
- [x] Unit-Tests, die den Endpunkt testen",9,https://gitlab.dit.htwk-leipzig.de/live-stream-editor-zur-korrektur-von-untertiteln/backend/-/issues/9,Closed,Benedikt Beigang,bbeigang,"Finn Johann Romeis, AMINE JEGANI","fromeis, ajegani",No,No,,2023-05-22 08:37:00,2023-06-17 09:05:39,2023-06-13 17:48:38,✏Sprint_02_2,2,Backend,0,67500,79,Bearbeiten/Navigieren
API Endpunkt - WebSocket Endpunkt von Speechmatics abbonieren,"Als interne Datenverwaltung im Backend benötige ich einen Endpunkt der den WebSocket von Speechmatics abboniert, sodass ich für einen gegebenen Audio-Stream  eine Transkription erhalte.

**Anmerkungen**
* Der [Link](https://docs.speechmatics.com/rt-api-ref) führt zur Beschreibung des WebSockets und wie die Kommunikation mit diesem abläuft.
* Es ist unter umständen ein API-Key notwendig, um auf den Endpunkt zugreifen zu können.
* Es reicht wenn eine Dummy-Audio-Datei verwendet wird.

**DoD**

- [x] Im Backend existiert ein Endpunkt Annahme der eine Audio-Datei häppchenweise dem WebSocket schickt und die Transkription entgegennimmt
- [x] Die Transkription als json, wird in unsere interne Datenstruktur überführt
- [x] Integration Tests wurden gemacht
- [x] Es wurde vor dem Wochenende eine Einschätzung gegeben ob das Ticket schaffbar ist in diesem Sprint",12,https://gitlab.dit.htwk-leipzig.de/live-stream-editor-zur-korrektur-von-untertiteln/backend/-/issues/12,Closed,Benedikt Beigang,bbeigang,"Christoph Neidahl, Luca Niklas Franke","cneidahl, lfranke2",No,No,,2023-05-22 08:37:00,2023-06-15 07:11:16,2023-06-14 18:56:14,✏Sprint_02_2,5,Backend,0,84600,77,Sichtbarkeit
Background Service -  Sprechblasen-Buffer Verwaltung,"Als API-Endpunkt der den fertig zusammengebauten Live-Stream zum Zielserver schickt, benötige ich eine Verwaltung des Sprechblasen-Buffers, der im Blick behält wann eine Sprechblase aus dem Timeframe rausfällt und fertig zum ausliefern ist.

**DoD**
- [x] Es existiert ein Background-Service der den Sprechblasen-Buffer verwaltet.
- [x] Ab einer festgelegtes Lebensdauer wandern die Sprechblasen aus dem Sprechblasen-Buffer und sind bereit mit der Audio und dem Video zusammengebaut zu werden.",18,https://gitlab.dit.htwk-leipzig.de/live-stream-editor-zur-korrektur-von-untertiteln/backend/-/issues/18,Closed,Benedikt Beigang,bbeigang,"Pascal Fabian Dittes, Luca Niklas Franke","pdittes, lfranke2",No,No,,2023-06-04 16:02:36,2023-06-13 17:51:01,2023-06-13 17:51:01,✏Sprint_02_2,5,Backend,0,28800,76,MVP Features
