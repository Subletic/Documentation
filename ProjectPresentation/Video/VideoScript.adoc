= Script f√ºr das 6 Min√ºtige Video
:toc:

== 1. Einleitung [15s (15/360)]

=== Notes
* Projekt Thema vorstellen, dabei auch auf das Hauptziel unsere Software eingehen
* Kurz wer sind wir also unsere Namen
* Name unseres Kunden
** Grundig Business Systems oder Grundig Business Systems GmbH & Co. KG

=== Text
Guten Tag und herzlich willkommen zur Projektpr√§sentation von Subletic. In diesem Video m√∂chten wir Ihnen unsere Software vorstellen, mit der die korrekte Untertitelung von Live-Streams zu einem Kinderspiel wird. Kommen Sie mit und lernen Sie unsere innovative Software-L√∂sung kennen.

=== Visual
1. Startfolie (10s)
1.1 Namen, etc.

image:start-folie.png[]

== 2. Problemstellung [60s (75/360)]

=== Notes
* nochmal zeigen was unser Kunde als Problem ausgeschrieben hat, hierbei bin ich mir nicht 100%ig sicher ob wir das brauchen
* k√∂nnte dann allgemeiner sein ("eine Software wie diese gibt es nicht?")
** hierbei vielleicht noch auf Anwendungsbereiche eingehen: Landtag usw. (macht einen sehr Professionellen eindruck ^^)
* Anforderungen des Kunden:
** DSGVO-Konform
** Mitdenken von Anforderungen von Stenografen

=== Text

Alice ist Stenografin f√ºr einen Landtag. Sie ist seit einigen Jahren in Ihrem Beruf schon t√§tig. Seit kurzem hat sie von den gro√üen Fortschritten in der Sprachsynthese geh√∂rt und fragt sich, ob auch sie davon profitieren kann. Jedoch wei√ü sie als Stenografin, wie wichtig korrekte Transkriptionen in politischen Kontexten sind und stellt sich deshalb die Frage: "_Kann ich der KI denn blind vertrauen?_". 

Nein, auch wenn die heutigen generativen Programme erstaunliches leisten, so ist in vielen Kontexten immer noch ein Mensch erforderlich, der der Maschine auf die Finger guckt. Und genau dabei m√∂chte unsere Software _Subletic_, Alice unterst√ºtzen. So hat Sie durch die automatische Sprachsynthese weniger Zeitdruck, den sie gut aus der Stenografie kennt, kann aber gleichzeitig sicher sein, dass die Transkription korrekt ist.

Gleichzeitig profitieren auch die Zuschauer vor den Bildschirmen und m√ºssen sich nicht mit schlechten generierten Untertiteln zufrieden geben. Und damit die Software auch tats√§chlich von Alice in Ihrem Landtag verwendet werden darf, ist sie oben drauf noch DSGVO-konform.

* Crazy Animation von Alice, das alte Haus üíÅ‚Äç‚ôÄÔ∏è

== 3. L√∂sung/Funktionalit√§t [60s (135/360)]

=== Notes
* eingehen auf die Bestehende Funktionalit√§t was haben wir bisher
** Wie eine Art "Demo" hauptfunktionalit√§ten der Software hervorheben
* wie funktioniert unsere Software f√ºr den Endnutzer

=== Text
Wie verwende ich _Subletic_?

1. Zun√§chst wird ein beliebiger Live-Stream eingelesen, zum Beispiel von einer Landtagsdebatte, wie bei Alice.
2. Nun erscheinen auf der Benutzeroberfl√§che nach und nach die erzeugten Transkriptionen, in sogenannten Sprechblasen. In einem festgesetzten Zeitfenster von einer Minute, k√∂nnen nun die fehlerhaften W√∂rter korrigiert werden.
3. Dabei unterst√ºtzt die Software bei der Identifikation von falsch erkannten W√∂rtern, indem die W√∂rter farbig markiert werden, bei denen die Speech-to-Text-Engine sich unsicher ist. 
4. Ein weiteres Hilfsmittel, welches Alice schon aus der Stenografie bekannt ist, ist ein Playback des Gesagten, in der vor und zur√ºck gesprungen werden kann. _[break]_ So kann sie sich vergewissern, ob die Transkription korrekt ist.
5. F√§llt eine Sprechblase aus dem Zeitfenster heraus, verschwindet sie von der Benutzeroberfl√§che und ist damit bereit f√ºr die Auslieferung an die Zuschauer.

Wir sehen dass _Subletic_ ein hilfreiches Werkzeug ist, welches Alice's Arbeit wesentlich vereinfacht.

// Homeoffice als Stenografin ist mittels unserer Software kinderleicht. [Zoom auf Monitor mit unserer Software, √ºbergang zur richtigen Software] (Bei switch ins Programm, l√§uft dann im Hintergrund l√§uft dann der Ton der Audio) Wie Sie sehen [Lautst√§rken Anpassung] l√§uft der Text ohne gr√∂√üere M√ºhen √ºber den Monitor. Hierbei ist es f√ºr Anwender einfach [Korrektur von einem Gelben/Rotem Wort] direkt in Fehlerhaft √úbersetzungen einzugreifen und somit Zuschauern ein vern√ºnftigen Untertitel zu liefern. *Denn was ist bl√∂der als Taub zu sein, schlie√ülich schlecht Untertitel*

=== Visual

Video von unserer Software die die genannten Features visualisieren

[options="header"]
|===
| Section | Topic | Visualisation
| 1. | Stream-einlesen | Animation
| 2. | Sprechblasen | Ankommenden Sprechblase zeigen
| 3. | Confidence-Werte | Umrandung der farbigen W√∂rter
| 4. | Audio-Spur | In der _[break]_ Audio-Schnippsel abspielen
| 5. | Zeitfenster | Verschwindene Sprechblase zeigen
|===

== 4. Technologien [60 (195/360)]
* Wie sieht eine Softwarel√∂sung aus?
* hervorheben der Wichtigsten Funktionen, welche vlt. auch von Philipp ausgerufen wurden
* hier erkl√§ren wir welche Tools und Libraries sich als hilfreich herausgestellt haben
** FFMpegCore
** SignalR
** Web-Audio-API
* Hier k√∂nnen wir auch auf die Vorteile unserer Software eingehen

=== Text

Nun m√∂chten wir auf die Technologien eingehen die verwendet wurden.
F√ºr Subletic haben wir auf ASP.NET 7 im Backend gesetzt, in dem die interne Verwaltung stattfindet. Dazu z√§hlt:

* der eingehende Stream
* die Kommunikation mit der Speech-to-Text-Engine
* die Sprechblasen
* sowie der Export der korrigierten Untertitel

Zudem nutzen wir FFMpegCore, um mit den verschiedenen Video- und Audio-Streams umgehen zu k√∂nnen.

Angular 16 ist das Ger√ºst f√ºr unser Frontend. SignalR gibt uns dabei die F√§higkeit unsere Sprechblasen, sowie das Audio, in unser Frontend zu streamen. Die Web-Audio-API bef√§higt uns anschlie√üend mit der Audio-Spur umzugehen, um Features wie das Navigieren in der Audio oder eine anpassbare Lautst√§rke, bereitzustellen. 

Beide Seiten unserer Software werden zun√§chst getrennt in einem eigenen Docker-Image bereitgestellt und anschlie√üend mit einer Docker-Compose zusammengef√ºhrt und deployed. Somit erreichen wir im Development eine klarere Trennung von Frontend und Backend.

== 5. Architektur [120s (315s/360)]

=== Text
Gehen wir nun ins Detail und betrachten die Architektur und internen Abl√§ufe, welche im Hintergrund stattfinden. Es sind drei relevante Bereiche zu sehen:

* Das Frontend welches mit Angular gebaut wurde,
* das Backenend welches unter ASP.NET l√§uft,
* und die Au√üenwelt, mit APIs, sowie Quell- und Ziel-Streams

Betrachten wir zun√§chst das Backend. Bevor ein Untertitel generiert werden kann, wird ein Audio-Stream ben√∂tigt, f√ºr den ein Untertitel erstellt werden soll. Dieser wird mithilfe von FFMpegCore innerhalb des AV-Processing Services eingelesen und in 1 sek√ºndige Pakete unterteilt. 

Die Audio-Pakete werden dann, nach und nach, an eine externe Speech-to-Text-Engine geschickt, welche daraufhin mit der generierten Transkription antwortet. (Zus√§tzlich tr√§gt die Antwort auch die Information, mit welcher Sicherheit ein Wort erkannt wurde.) Gleichzeitig wird die Audiospur direkt ins Frontend gestreamt, sodass diese geh√∂rt werden kann.

Die erhaltenen Transkriptionen werden nun mithilfe des Word-Processing-Services in sogenannte _Sprechblasen_ umgewandelt. Sie stellen eine kleine Folge von W√∂rtern da und werden vom Speechbubble-Service verwaltet. 

Um sicherzustellen, dass die eingelesenen Transkriptionen und der eingegangene Audio-Stream schlie√ülich das Backend verlassen und dem Endkunden ausgespielt werden, kommt der Buffer-Time-Monitor zum Einsatz. Er √ºberwacht den internen Zustand der Sprechblasen, sowie des Audios und st√∂√üt alle notwendigen L√∂sch- und Export-Prozesse an, sobald Daten aus einem festgelegten Zeitfenster fallen.

F√ºr die Kommunikation mit dem Frontend, verwenden wir den Speechbubble-Controller. Dieser stellt alle notwendigen Schnittstellen zur Verf√ºgung, um neue Sprechblasen anzuzeigen, zu l√∂schen oder Korrekturen entgegenzunehmen.

Das Frontend nimmt die vom Speechbubble-Controller gesendeten SignalR-Streams mit den Sprechblasen an und speichert diese in der Speechbubble-Chain. Sie stellt die Frontend-seitige Datenstruktur da, welche die Sprechblasen in einer Liste vorh√§lt. Diese kann dann dazu genutzt werden, die jeweiligen Sprechblasen in Textboxen zu visualisieren. Werden vom Anwender einige W√∂rter ver√§ndert, l√∂st dies einen Update-Call aus, welcher die ge√§nderte Sprechblase an das Backend schickt. 

(Parallel dazu werden die eingehenden Audio-Pakete in einem Ring-Buffer abgelegt und verwaltet. So kann das Frontend den Buffer jederzeit verwenden, um die Audiospur auszulesen und zu manipulieren.)

== 6. Ausblick [60s (375/360)]
=== Notes
* Hier w√ºrde ich sagen gehen wir darauf ein wie wir unsere Software weiter verbessern, weiterentwickeln
** Hardware Komponenten vielleicht sogar an dem Tag mit bringen zum zeigen?
*** Vielleicht sogar hierf√ºr Bilder verwenden von den Ger√§ten selbst

=== Text

Wir haben gesehen wie mit _Subletic_ schon jetzt fehlerhaft generierte Untertitel m√ºhelos korrigiert werden k√∂nnen. In einem n√§chsten Schritt, wollen wir uns der Auslieferung an den Endkunden widmen. Eine entscheidende Fragestellung ist dabei, wie wir die generierten Transkriptionen so portionieren, dass gut lesbare Untertitel, auf dem Bildschirm erscheinen.

Au√üerdem wollen wir den Korrektur-Workflow von _Subletic_ optimieren indem wir dem Anwender weitere Hilfen anbieten, um schneller und effizienter zu Korrigieren. Dies ist vor allem in stressigen Situationen von Vorteil, wenn die Speech-to-Text-Engine viele Fehler macht und daher auch viele Korrekturen notwendig sind. Perspektivisch m√∂chten wir _Subletic_ mit Wortvorschl√§gen erg√§nzen, um kostbare Zeit einzusparen. Diese k√∂nnten entweder aus schon korrigierten oder phonetisch √§hnlichen W√∂rtern generiert werden.
Ein weiterer Ansatzpunkt, welchen wir verfolgen m√∂chten ist die Integration von Hand- und Fu√üschaltern, sodass Stenografen mit bekannten Eingabeger√§ten arbeiten k√∂nnen. 

(Grunds√§tzlich wollen wir die visuelle Kommunikation mit dem Nutzer verbessern, sodass sich Anwender schneller zurechtfinden und orientieren k√∂nnen.)

== 7. Ende [15s (390/360)]

=== Text

Wir hoffen wir konnten Sie von _Subletic_ √ºberzeugen und freuen uns auf ihr Feedback. Sollten noch Fragen offen geblieben sein, sprechen sie uns gerne an. Wir danken allen Beteiligten, im besonderen unserem Projektsponsor, der GRUNDIG Business Systems GmbH & Co. KG.

