Da unsere Software von jungen Entwicklern programmiert wird, haben wir von Anfang an auf Code-Reviews, Unit-Tests und Linting in der CI-Pipeline gesetzt, um die Qualität unseres Codes zu gewährleisten. Erfahrende Teammitglieder unterstützen die jungen Entwickler durch Code-Reviews und geben ihr Wissen weiter. So haben wir eine durchschnittliche Methoden-Komplexität von 2 und eine Klassenkopplung von 16. Die durchschnittlichen Zeilen pro Methode beträgt 6 und die von Klassen 125. Die Line-Coverage liegt bei 66% im Backend und 75% im Frontend. Um die User-Experience zu verbessern, sind unsere Frontend-Entwickler angehalten die 60:30:10-Faustregel anzuwenden. Diese hilft uns ein schlichtes und stimmiges Design durchzusetzen und den Blick des Anwenders durch Akzentfarben zu lenken.

---

Zum Release unserer Software konnten alle Kernfeatures realisiert werden. Wir bieten einen abonnierbaren WebSocket-Service an, mit dem ein Audio-Stream transkribiert wird. Außerdem haben wir eine Web-Anwendung entwickelt, mit dem die generierten Transkriptionen korrigiert werden können. Diese werden in einer Liste von sogenannten Sprechblasen dargestellt und können editiert werden. Dabei unterstützt unser Tool die korrigierende Person indem Wörter hervorgehoben werden, die vermutlich falsch erkannt wurden. Parallel wird der Audio-Stream für den Anwender abgespielt und ihm visuell angezeigt, welches Wort gerade gesagt wird. Um sich zu vergewissern ob ein Wort richtig erkannt wurde, kann der Nutzer vor und zurück springen und dabei auch die Wiedergabegeschwindigkeit anpassen. Eingabegeräte wie Hand und Fußschalter werden unterstützt, um die Bedienung zu erleichtern. Wörter die häufig falsch erkannt werden, wie zum Beispiel Eigennamen oder Fachbegriffe, können in einem Wörterbuch gespeichert werden und sorgen so für eine verbesserte Worterkennung.

---

Unsere Software erlaubt es dem Nutzer, die aus dem Eingabe-Stream generierte Transkriptionen, in sogenannte Sprechblasen, in einer Liste zu sehen und zu editieren. Zudem werden Wörter, bei dem sich die Speech-To-Text Engine unsicher ist, mit sogenannten Konfidenzwerten, farbig markiert. Zusätzlich zur reinen visuellen Repräsentation des Gesagten, ist laufend das Audio des Video-Streams zu hören. Dies bietet die Grundlage, dass sich der Stenograf vergewissern kann, fehlerhafte Wörter zu korrigieren. Außerdem ist möglich, in der Audio vor und zurückzuspringen, um bei Unsicherheiten sich nochmal zu vergewissern. Die Zeitspanne, ab wann Sprechblasen und der Audio-Stream aus dem Zeitfenster zur Bearbeitung verschwinden ist durch den Nutzer individuell Anpassbar. Des Weiteren besitzt die Software die Möglichkeit häufig fehlerhaft erkannte Wörter in einem sogenannten Dictionary zu speichern und diese an die Speech-Engine zu übertragen. Somit ist es von Beginn an möglich potenzielle Fehlerquellen zu eliminieren und dem Stenografen vermehrt Arbeit abzunehmen.