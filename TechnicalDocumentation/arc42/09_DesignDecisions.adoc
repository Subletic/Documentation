<<<

== Entscheidungen

Hier werden wichtige Entscheidungen festgehalten, welche im Laufe des Projektes getroffen wurden.

[options="header", cols=","]
|===
| Name | Eingabe- und Ausgabe-Format
| Kontext | Aus Sicht des Clients ist es das Hauptziel unserer Software, Untertitel zu erzeugen. Da wir nach außen Betrachtet einen Service anbieten, müssen wir spezifizieren was wir als Eingabe-Stream akzeptieren und was wir am Ende zurück geben. 
| Entscheidung | Der WebSocket-Server erwartet einen Video- oder Audio-Stream, solange dieser mit FFmpeg verarbeitet werden kann. Sollte jedoch ein Video-Stream geschickt werden, wird dieser weggeworfen. 
| Konsequenzen | Es werden ausschließlich reine Untertitel zurück gegeben, es nicht möglich den erzeugten Untertitel in das Video einzubetten und diesen als Video-Stream zurück zu geben.
| Status | pass:[<span style="color: green;">Umgesetzt</span>]
|===

[options="header", cols=","]
|===
| Name | Untertitelformate
| Kontext | Es muss spezifiziert werden welche Untertitelformate wir unterstützen.
| Entscheidung | Wir unterstützen das WebVtt- und SRT-Format.
| Konsequenzen | Veraltete Systeme, welche nicht die angegeben Formate unterstützen, können nicht mit unserem Service arbeiten.
| Status | pass:[<span style="color: green;">WebVtt Umgesetzt</span>], pass:[<span style="color: red;">SRT in Planung</span>]
|===

[options="header", cols=","]
|===
| Name | Wiedergabegeschwindigkeiten und Pitch 
| Kontext | Unsere Software bietet die Möglichkeit an die Wiedergabegeschwindigkeit zu ändern, in der, der Audio-Stream abgespielt wird. Ändert man die Abspielgeschwindigkeit jedoch, ändert sich durch die Frequenz und damit der Pitch, sodass sich Stimmen quitschig oder zu tief anhören. Die WebAudio-API welche wir für das Abspielen des Sound im Frontend nutzen, korrigiert jedoch nicht in Live-Kontexten den Pitch. Zusätzliche Bibliotheken welche den Pitch korrigieren, sorgen jedoch für Audio-Artefakte.
| Entscheidung | Mit dem Kunden wurde vereinbart, dass wir die Wiedergabegeschwindigkeit begrenzen auf 0.7 bis 1.3, und den Pitch nicht korrigieren, damit zumindest keine Artefakte entstehen.
| Konsequenzen | Der Kunde muss sich mit der begrenzten Wiedergabegeschwindigkeit zufrieden geben, sowie mit unnatürlichen Stimmen, je nach Geschwindigkeitsänderung.
| Status | pass:[<span style="color: green;">Umgesetzt</span>]
|===

[options="header", cols=","]
|===
| Name | Umbau der Backend-zu-Frontend Kommunikation 
| Kontext | Derzeit verwenden wir einen SignalR-Hub, um die Kommunikation zwischen Backend und Frontend zu realisieren. Dieser Hub wird jedoch von verschiedenen Stellen unseres Backends direkt aufgerufen, bzw. direkt über diesen Daten an das Frontend geschickt. 
| Entscheidung | Wir wollen einen neuen Service implementieren, welcher die Kommunikation zwischen Backend und Frontend übernimmt. Dieser Service soll die Daten von den verschiedenen Stellen unseres Backends entgegennehmen und diese dann an das Frontend weiterleiten.
| Konsequenzen | Bessere Kapselung von Aufgaben, sodass Backend-Logik und Sende-Prozesse getrennt werden.
| Status | pass:[<span style="color: green;">Umgesetzt</span>]
|===

[options="header", cols=","]
|===
| Name | Formate des exportierten _Soundslike_-Dictionaries 
| Kontext | Zur Übertragung des _Soundslike_-Dictionaries an Speechmatics wird json verwendet. Jedoch ist dies ein unhandliches Datei-Format für unsere User, wenn sie diese lokal bearbeiten und exportieren möchten. 
| Entscheidung | Support von verschiedenen Dateiformaten, wie CSV, XLS, XLSX
| Konsequenzen | Es entsteht eine weitere Abstraktionsebene
| Status | pass:[<span style="color: green;">CSV Umgesetzt</span>], pass:[<span style="color: red;">XLS in Planung</span>], pass:[<span style="color: red;">XLSX in Planung</span>]
|===

[options="header", cols=","]
|===
| Name | Verschiedene Kommunikationswege zwischen Backend und Frontend
| Kontext | Historisch gewachsen, verwenden wir für die Kommunikation vom Frontend zum Backend, REST und für die Kommunikation vom Backend zum Frontend, SignalR. Die Frage ist ob es die Wartbarkeit erhöht, wenn wir nur noch einen Kommunikationsweg (SignalR) verwenden.
| Entscheidung | Diese Idee wurde wieder verworfen, da der Aufwand nicht den Nutzen rechtfertigt und der Empfangsprozess im Backend dadurch unnötig verkompliziert wird. 
| Konsequenzen | Es bleibt bei zwei Art und Weisen Informationen zwischen Backend und Frontend auszutauschen.
| Status | pass:[<span style="color: orange;">Verworfen</span>]
|===

[options="header", cols=","]
|===
| Name | Aufteilung der Klassen in Komponenten/Ordner
| Kontext | Durch die fortschreitende Entwicklung unseres Projektes, wächst die Anzahl der Klassen, sodass die bisherige Ordnerstruktur, welche die Klassen nach ihrer Art unterscheidet (Service, Controller, Model, etc.), für Unübersichtlichkeit sorgt.
| Entscheidung | Es sollte eine neue Aufteilung in Ordner geben, die statt der Art der Klasse, die Aufgabe als Teil einer Software-Komponente verwendet. Zum Beispiel Audio, SpeechBubble, etc.
| Konsequenzen | Das Refactoring bzw. die Umstrukturierung führt zu einer besseren Übersichtlichkeit und Wartbarkeit, jedoch blockiert Sie auch die Weiterentwicklung der Software, da sonst mit komplizierten Merge-Requests zu rechnen ist.
| Status | pass:[<span style="color: red;">Backend in Planung</span>], pass:[<span style="color: red;">Frontend in Planung</span>]
|===