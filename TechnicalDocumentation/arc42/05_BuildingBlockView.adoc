:imagesdir: ./img
<<<

== Bausteinsicht

Dieser Abschnitt beschreibt die Bausteinsicht der Software _Subletic_. Wir starten mit einem abstrakten Überblick des Datenflusses und gehen vor dort aus, über die Komponenten, bis wir bei der Modulübersicht angelangt sind, welche die detaillierteste Sicht darstellt.

=== Daten-Sicht

Um die verschiedenen Bausteine von _Subletic_ zu verstehen, hilft es zunächst einen Blick auf die wichtigsten Daten und deren Verarbeitung zu werfen, welche zur Laufzeit existieren. Sie geben eine abstrakte Übersicht was zur Laufzeit passiert. Für eine Gegebene Audio wird zunächst extern eine Transkription erstellt, die anschließend in die interne Datenstruktur namens _SpeechBubble_ überführt wird. Sie stellt eine frühe Version des Untertitels da und besteht nur aus ein paar Wörtern, die zeitlich betrachtet eine Einheit darstellen. Diese können dann so lange sie existieren, manipuliert werden. Zum Schluss werden die _SpeechBubbles_ zu einem fertigen Untertitel konvertiert, welche ausgeliefert werden können.

.Datenfluss von Subletic
image::Datenfluss.drawio.svg[Static,80%,align="center"]

Nachdem geklärt wurde welche Daten verarbeitet werden, betrachten wir im nächsten Schritt welche Fremdsysteme und Benutzer an welchen Daten(-verarbeitungen) beteiligt sind. Dazu werfen wir nochmal einen Blick auf alle Beteiligten und mit welchen Daten sie zu tun haben:

****
1. Der Client möchte für einen Video-Stream einen **Untertitel** erhalten und sendet dazu einen **Audio**-Stream an Subletic.
2. Eine Speech-Engine wird benötigt, welche den **Audio**-Stream in eine **Transkription** umwandelt. 
3. Die korrigierenden Person benötigt eine Schnittstelle zu unserer Software, um die generierten **Transkription** anpassen zu können. Sie möchte dabei den **Audio**-Stream hören.
****

Da die Audio-Daten von allen Parteien verwendet werden, findet die Verarbeitung im Backend statt mit dem alle interagieren können. Da die generierte Transkription, sowie auch der fertige Untertitel, für das direkte Bearbeiten eher unhandlich ist, fügen wir eine neue interne Datenstruktur namens _SpeechBubble_ ein, die als Mittelstück dient. Alle drei Daten-Typen liegen ebenfalls im Backend, um die verschiedenen Parteien verbinden zu können. Anders als bei den Fremdsystemen, benötigt die korrigierende Person ein graphisches Interface, um die _SpeechBubbles_ bearbeiten zu können. Dazu wird ein Frontend benötigt, über das auch der Audio-Stream abgespielt werden kann. Da nun die Software aus zwei Bereichen besteht, benötigen wir nun zusätzliche Schnittstellen, um Frontend und Backend zu verbinden.

=== Ebene 1 - Komponenten-Sicht

Wir gehen nun eine Ebene tiefer und betrachten welche Komponenten nötig sind, um die verschiedenen Daten entgegenzunehmen, zu verwalten, zu verarbeiten und weiterzuschicken. Neben den API-Bereichen die für die Kommunikation mit den Fremdsystemen benötigt werden, tauchen die Domänen: _Audio_, _SpeechBubble_ und _Configuration_ in Backend und Frontend auf. Sie stellen die Grundpfeiler unserer Software-Architektur dar.

==== Backend

Unser ASP.NET-Backend besteht aus vier Komponenten. Die _Client-Communication_-API kapselt die Kommunikation mit unserem Client. Sie empfängt den eingehenden Audio-Stream und überträgt den fertigen Untertitel zurück. Die _Audio_-Domäne erhält von der _Client-Communication_-API den Audio-Stream und leitet diesen direkt weiter an unsere Speech-Engine. Diese antwortet mit einer Transkription, welche später als Untertitel dient. Die rohe Transkription wird anschließend an die _SpeechBubble_-Domäne weitergeleitet, wo sie zur internen _SpeechBubble_-Datenstruktur übersetzt wird. Diese stellt eine früher Version der Untertitel dar, welche benötigt wird um Teile des Untertitels zu korrigieren. Nach Ablauf einer bestimmten, einstellbaren Zeit, werden einzelne _SpeechBubbles_ zu einem echten Untertitel umgewandelt und mit Hilfe der _Client-Communication_-API an den Client ausgeliefert. 

.Komponenten-Sicht des Backends
image::Bausteinsicht_1_Backend.drawio.svg[Static,80%,align="center"]

Dieser Kreislauf läuft autonom ab, kann jedoch durch die korrigierende Person bei Bedarf ergänzt werden. Dazu wird die _Frontend-Communication_-API benötigt, welche die Kommunikation mit dem Frontend übernimmt. Zunächst wird diese durch die _Audio_-Domäne dafür genutzt den Audio-Stream an das Frontend weiter zu leiten, sodass dieser gehört werden kann. Außerdem wird die _Frontend-Communication_-API genutzt um neue _SpeechBubbles_ an das Frontend zu senden, um korrigierte _SpeechBubbles_ zu empfangen und über das Ableben von _SpeechBubbles_ zu informieren.

==== Frontend

Unser Angular-Frontend besteht aus vier Komponenten. Analog zum Backend, wird die _Backend-Communication_-API genutzt um Daten zum Backend zu Senden oder entgegenzunehmen. Der empfangene Audio-Stream wird innerhalb der _Audio_-Domäne verarbeitet, modifiziert und für die korrigierenden Person abgespielt. Gleiches gilt für die empfangenen SpeechBubbles. Diese werden entgegengenommen und an die _SpeechBubble_-Domäne weitergeleitet. Stößt die korrigierende Person die Bearbeitung einer _SpeechBubble_ an, wird sie über den selben Weg an das Backend zurückgesendet. Wird ein Sprung in der Position des Audio-Streams (und daraus resultierend die Position des Cursors) ausgelöst, wird dies an die _Audio_-Domäne und die _SpeechBubble_-Domäne kommuniziert.

.Komponenten-Sicht des Frontends
image::Bausteinsicht_1_Frontend.drawio.svg[Static,80%,align="center"]

Isoliert davon wird die _Configuration_-Domäne genutzt, die Konfiguration der Software beim Start des Korrektur-Prozesses an alle betreffenden Komponenten und Fremdsysteme zu kommunizieren. So kann Initial ein _Soundslike-Dictionary_ als Tabellen-Datei übergeben und bearbeitet werden, um der _SpeechEngine_ bei der Erkennung schwieriger Wörter zu helfen. Außerdem werden _Initiale Parameter_, wie die Länge des Zeitintervalls in der eine Sprechblase existiert, hier übergeben. Die gebündelte Start-Konfiguration wird mit Hilfe der _Backend-Communication_-API an das Backend gesendet und damit die Software, beziehungsweise der Korrektur-Prozess gestartet.

=== Ebene 2 - Modul-Sicht

Auf dieser Ebene werden die Bestandteile der Komponenten aufgelistet und kurz ihr Existenzgrund erläutert.

==== Backend

.Modul-Sicht des Backends
image::Bausteinsicht_2_Backend.drawio.svg[Static,100%,align="center"]

.Client-Communication
****
[options="header", cols=","]
|===
| Modul | Beschreibung
| ClientExchangeController | Hält den WebSocket zum Client
| IAvReceiverService | Empfängt den Audio-Stream vom Client und leitet ihn an den AvProcessingService weiter
| ISubtitleExportService | Hält den ISubtitleConverter und leitet die Untertitel an den Client weiter
| ISubtileConverter | Konvertiert SpeechBubbles zu Subtitles
|===
****

.SpeechBubble
****
[options="header", cols=","]
|===
| Modul | Beschreibung
| ISpeechBubbleService | Hält die SpeechBubbles bereit und bietet die Informationen dem Rest des Backends an.
| BufferTimeMonitor | Überwacht die Lebenszeit der SpeechBubbles und stößt die Konvertierung in Untertitel an, wenn sie abgelaufen sind.
| IWordProcessingService | Wandelt generierte Transkriptionen der Speech-Engine in SpeechBubbles um und fügt sie dem ISpeechBubbleService hinzu.
|===
****

.Frontend-Communication
****
[options="header", cols=","]
|===
| Modul | Beschreibung 
| ConfigurationController | Empfängt die Konfiguration
| SpeechBubbleController | Empfängt aktualisierte SpeechBubbles
| FrontendCommunicationService | Stellt Kommunikation mit Frontend ausgehend vom Backend bereit, wie das Bekanntmachen neuer SpeechBubbles. Hält den FrontendCommunicationHub.
| FrontendCommunicationHub | Kümmert sich um das Senden des Audio-Streams
|===
****

.Configuration
****
[options="header", cols=","]
|===
| Modul | Beschreibung
| ConfigurationService | Hält die durch das Frontend bereitgestellte Konfiguration bereit und bietet die Informationen dem Rest des Backends an.
|===
****

.Audio
****
[options="header", cols=","]
|===
| Modul | Beschreibung
| AvProcessingService | Kümmert sich um die Verarbeitung des Audio-Streams, wie das Umwandeln in in ein von Speechmatics verarbeitbares Audio-Format.
|===
****

.Speech-Engine
****
[options="header", cols=","]
|===
| Modul | Beschreibung
| SpeechmaticsConnectionService | Hält den WebSocketClient zur Speechmatics-API, und initialisiert die Verbindung.
| SpeechmaticsSendService | Übermittelt den Audio-Stream an die Speechmatics-API.
| SpeechmaticsResponseService | Empfängt die Transkription von der Speechmatics-API und leitet sie an den WordProcessingService weiter.
|===
****

==== Frontend

.Modul-Sicht des Frontends
image::Bausteinsicht_2_Frontend.drawio.svg[Static,100%,align="center"]

.SpeechBubble
****
[options="header", cols=","]
|===
| Modul | Beschreibung
| textSheet | Hauptbereich in dem die SpeechBubbles angezeigt werden.
| speechbubble | Einzelne SpeechBubble.
| word | Einzelnes Wort in einer SpeechBubble.
|===
****

.Configuration
****
[options="header", cols=","]
|===
| Modul | Beschreibung
| configuration.service | Hält die Konfiguration, wie Soundslike-Dictionary und Delay, bereit und bietet die Informationen dem Rest des Frontends an.
| startPage | Startseite, auf der die Konfiguration eingegeben wird.
| start-config | Sub-Komponente der Startseite, die Parameter wie den Delay entgegennimmt.
| continue-popup | Sub-Komponente die erscheint, bevor der User final zum Korrektur-Prozess weitergeleitet wird.
| dictionary-editor | Sub-Komponente der Startseite, die das Soundslike-Dictionary zum Bearbeiten anbietet.
| dictionary-row | Einzelne Zeile des Soundslike-Dictionary.
| dictionary-fs-loader | Sub-Komponente der Startseite, in der Dictionary-Dateien importiert und exportiert werden können, sowie Komfortfunktionen zum Bearbeiten des Dictionaries.
| dictionary-popup | Sub-Kompontente des dictionary-fs-loader, die das Importieren und Exportieren von Dictionary-Dateien ermöglicht.
| dictionary-export.interface | Bietet die Schnittstelle für das Exportieren von Dictionary-Dateien und die dazu notwendigen Konvertierungs-Funktionen.
|===
****

.Backend-Communication
****
[options="header", cols=","]
|===
| Modul | Beschreibung
| backendListener.service | Empfängt die vom Backend gesendeten Daten, wie den Audio-Stream und die SpeechBubbles.
| backendProvider.service | Stellt die Kommunikation mit dem Backend bereit, wie das aktualisieren von SpeechBubbles oder den Configuration-Upload.
|===
****

.Audio
****
[options="header", cols=","]
|===
| Modul | Beschreibung
| audiohandler | Kümmert sich um das Playback und das Buffering des Audio-Streams.
| audio.service |
| soundbox | Komponente auf der Hauptseite die für die Manipulation des Audio-Streams zuständig ist.
| slider-popup | Sub-Komponente der soundbox, die die Lautstärke des Audio-Streams regelt.
| speed-popup | Sub-Komponente der soundbox, die die Abspielgeschwindigkeit des Audio-Streams regelt.
|===
****

.Device
****
[options="header", cols=","]
|===
| Modul | Beschreibung
| hid-control.service | Regelt die Kommunikation der Eingabegeräte mit dem Frontend.
|===
****

.settings
****
[options="header", cols=","]
|===
| Modul | Beschreibung
| settings | Komponente auf der Hauptseite, die die Einstellungen des Frontends regelt, wie die Sprungweite des Vorspulens.
| settings.service | Hält die Einstellungen bereit und bietet die Informationen dem Rest des Frontends an.
|===
****